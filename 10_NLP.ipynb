{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolasvazquez95/Aprendiendo_DeepLearning/blob/main/10_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get data - Tokenization and Embedding"
      ],
      "metadata": {
        "id": "tPAO4fjoZ57Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "868vEm2pPBy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42235c8-6999-401b-9f93-78b9c2d1d4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-16 16:34:50--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-16 16:34:50 (60.5 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "import helper_functions as helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFgsbvOaQ7kF",
        "outputId": "916d5810-e37d-4cce-ba0b-40b7065d04a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-16 16:34:51--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 64.233.166.128, 74.125.71.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2022-05-16 16:34:51 (104 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the text dataset\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "helper.unzip_data('nlp_getting_started.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nht8UMGURenv",
        "outputId": "51fc80a6-c719-4ad9-9c37-ed8caa75220e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de2af598-7780-48ee-9074-16ae05d68b57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de2af598-7780-48ee-9074-16ae05d68b57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de2af598-7780-48ee-9074-16ae05d68b57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de2af598-7780-48ee-9074-16ae05d68b57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Tj8n1cKEjq8v",
        "outputId": "703d9b15-7aeb-4a32-ef81-fb98c6664c4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07d0d598-9ad4-429d-894d-f02c01d6ec32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07d0d598-9ad4-429d-894d-f02c01d6ec32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07d0d598-9ad4-429d-894d-f02c01d6ec32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07d0d598-9ad4-429d-894d-f02c01d6ec32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Shuffle\n",
        "train_df_shuffled = train_df.sample(frac=1,random_state=42)\n",
        "train_df_shuffled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w7d691AxkBwq"
      },
      "outputs": [],
      "source": [
        "# Split data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = train_df_shuffled['text'].copy()\n",
        "y = train_df_shuffled['target'].copy()\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.15,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenization\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "dY4wrW-7muCx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(X_train)"
      ],
      "metadata": {
        "id": "zsqmdw6O79xx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmeM2-OyCRSe",
        "outputId": "39b74742-88aa-4a5f-e18a-fb99ded671ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[252,   3, 244,   4,  13, 727,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "id": "mPQX-ugiCbFM",
        "outputId": "35af289b-5e9b-4067-b695-b4c7ba3eb665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['noahanyname', 'noah', 'no2', 'nnw', 'nno']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Embedding Layer\n",
        "embedding = keras.layers.Embedding(input_dim=max_vocab_length,\n",
        "                                   output_dim=128,\n",
        "                                   input_length=max_length)"
      ],
      "metadata": {
        "id": "lCH-AdG1VZyT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_sentence = random.choice(X_train)\n",
        "print(f'Original text:\\n {random_sentence}\\\n",
        "\\n\\nEmbedded version:\\n')\n",
        "#Embedded version\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThIhEewMWnZD",
        "outputId": "20ca0930-8af9-44b1-9ced-0c6d1fa0abb7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " I know it's a question of interpretation but this is a sign of the apocalypse.  I called it https://t.co/my8q1uWIjn\n",
            "\n",
            "Embedded version:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.01142566,  0.00125264, -0.02954164, ...,  0.0331663 ,\n",
              "         -0.00307534, -0.04909436],\n",
              "        [ 0.00311036,  0.00983224,  0.04595358, ..., -0.01868846,\n",
              "          0.00816754, -0.02888161],\n",
              "        [-0.01222702, -0.02359438, -0.02720351, ...,  0.04552272,\n",
              "          0.00627636, -0.00946717],\n",
              "        ...,\n",
              "        [ 0.02290528,  0.02146382, -0.04418736, ..., -0.0267189 ,\n",
              "          0.02797374, -0.03323121],\n",
              "        [ 0.00167676,  0.01227218, -0.00221572, ...,  0.01482412,\n",
              "          0.0159439 ,  0.0439803 ],\n",
              "        [ 0.03809874,  0.0365029 , -0.02225101, ..., -0.04683873,\n",
              "          0.03840974, -0.01186135]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 0 : Naive Bayes (Scikit)"
      ],
      "metadata": {
        "id": "QCRebsOLZx3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([('tfidf',TfidfVectorizer()),\n",
        "                    ('clf',MultinomialNB())])\n",
        "model_0.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctc996N1Z11S",
        "outputId": "b3eeea89-120b-46b2-c3ce-020c6d842881"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I868EMPHboKM",
        "outputId": "65b125b8-9750-4a96-9c19-bb28682a2693"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8003502626970228"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "syi6kjCubtLY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "y_pred_0 = model_0.predict(X_test)\n",
        "\n",
        "baseline_results = calculate_results(y_true=y_test,\n",
        "                                     y_pred=y_pred_0)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qikv13xBct2v",
        "outputId": "8cf226e0-1822-4883-924d-eef032e70f25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.03502626970229,\n",
              " 'f1': 0.7937090801534213,\n",
              " 'precision': 0.8170270320769228,\n",
              " 'recall': 0.8003502626970228}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1 : Simple Dense model"
      ],
      "metadata": {
        "id": "H7Un9n65dqbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback\n",
        "SAVE_DIR = 'model_logs'\n",
        "\n",
        "# Build model Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_1 = keras.Model(inputs,outputs)\n",
        "\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "p_AzoapaduU3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.fit(X_train,y_train,\n",
        "            epochs=5,\n",
        "            validation_data=(X_test,y_test),\n",
        "            callbacks=[create_tensorboard_callback(SAVE_DIR,'model_1_dense')]\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll0xLOJ0AEYi",
        "outputId": "37d3c817-0aec-446c-96ca-f586ce0c6f80"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20220516-163459\n",
            "Epoch 1/5\n",
            "203/203 [==============================] - 9s 14ms/step - loss: 0.6184 - accuracy: 0.6885 - val_loss: 0.5442 - val_accuracy: 0.7461\n",
            "Epoch 2/5\n",
            "203/203 [==============================] - 2s 11ms/step - loss: 0.4479 - accuracy: 0.8163 - val_loss: 0.4774 - val_accuracy: 0.7846\n",
            "Epoch 3/5\n",
            "203/203 [==============================] - 2s 11ms/step - loss: 0.3493 - accuracy: 0.8609 - val_loss: 0.4658 - val_accuracy: 0.7907\n",
            "Epoch 4/5\n",
            "203/203 [==============================] - 3s 12ms/step - loss: 0.2859 - accuracy: 0.8881 - val_loss: 0.4674 - val_accuracy: 0.7890\n",
            "Epoch 5/5\n",
            "203/203 [==============================] - 2s 12ms/step - loss: 0.2386 - accuracy: 0.9104 - val_loss: 0.4824 - val_accuracy: 0.7872\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e5476d810>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get results\n",
        "y_pred_1 = tf.squeeze(tf.round(model_1.predict(X_test)))\n",
        "calculate_results(y_test,y_pred_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgSSb_BG-Skr",
        "outputId": "768b0458-277f-4761-8fdb-2f05591eea6f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.7215411558669,\n",
              " 'f1': 0.7836218881747316,\n",
              " 'precision': 0.7915324377310113,\n",
              " 'recall': 0.787215411558669}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize learned embeddings"
      ],
      "metadata": {
        "id": "yTXkxxHpGhkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words = text_vectorizer.get_vocabulary()"
      ],
      "metadata": {
        "id": "JigWILpJGlDb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5OKLkjcAXYn",
        "outputId": "005382e1-4eb7-4535-f141-f507bbf57a25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weight matrix of the embedding layer contains the numerical representations of each token in our training data, which have been learned for 5 epochs."
      ],
      "metadata": {
        "id": "ehhrYz_5_sKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_weights = model_1.get_layer('embedding').get_weights()[0]"
      ],
      "metadata": {
        "id": "O1hrs2d0AK1h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embedding files for visualization\n",
        "import io\n",
        "\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embedding_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "6t657kiiCarj",
        "outputId": "9277e2fb-53cf-489f-cd3b-5fd5e4e51daf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_218ffce7-63a3-4216-8168-4b50ab8746d7\", \"vectors.tsv\", 15376276)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ebe5f39-c87a-4739-8e3e-f82a853e9368\", \"metadata.tsv\", 80506)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 : LSTM"
      ],
      "metadata": {
        "id": "vRFHT8dhL6eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LSTM model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,),dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.LSTM(64,return_sequences=True)(x) # stacking\n",
        "x = layers.LSTM(64)(x)\n",
        "#x = layers.Dense(64,activation='relu')(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs,outputs,name='model_2_LSTM')"
      ],
      "metadata": {
        "id": "7mhbiSqiMNRL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChkvtoZZNijt",
        "outputId": "3d0ae66c-bbfa-41e0-ca1b-17c90fb5cb7c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 15, 64)            49408     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,362,497\n",
            "Trainable params: 1,362,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss='binary_crossentropy',optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vrZ9lsTCQS7e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(X_train,\n",
        "                              y_train,\n",
        "                              epochs=5,\n",
        "                              validation_data=(X_test,y_test),\n",
        "                              callbacks=create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                    'model_2_LSTM'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwnK09MnQcYR",
        "outputId": "cc0061a4-2ba1-4d49-e13e-bd0cbe6740ca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220516-163523\n",
            "Epoch 1/5\n",
            "203/203 [==============================] - 10s 20ms/step - loss: 0.2182 - accuracy: 0.9227 - val_loss: 0.5504 - val_accuracy: 0.7767\n",
            "Epoch 2/5\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.1536 - accuracy: 0.9437 - val_loss: 0.6286 - val_accuracy: 0.7741\n",
            "Epoch 3/5\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.1258 - accuracy: 0.9543 - val_loss: 0.7104 - val_accuracy: 0.7706\n",
            "Epoch 4/5\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.1034 - accuracy: 0.9598 - val_loss: 0.7768 - val_accuracy: 0.7627\n",
            "Epoch 5/5\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.0769 - accuracy: 0.9683 - val_loss: 1.1167 - val_accuracy: 0.7741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_preds = tf.squeeze(tf.round(model_2.predict(X_test)))\n",
        "\n",
        "calculate_results(y_test,model_2_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoVITTEzRApm",
        "outputId": "a301dda3-9dd0-4aee-ae5b-ea295a647465"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.40805604203153,\n",
              " 'f1': 0.7729642429408159,\n",
              " 'precision': 0.7735937234911502,\n",
              " 'recall': 0.7740805604203153}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: GRU"
      ],
      "metadata": {
        "id": "4ok8JfckR3uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(1,),dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64,return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64,activation='relu')(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs,outputs,name='model_3_GRU')"
      ],
      "metadata": {
        "id": "OXKq1-IVR48p"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDp_8Fn3We4M",
        "outputId": "3b7227fc-cc53-4753-897e-f06e7dbe26ad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 15, 64)            37248     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,346,433\n",
            "Trainable params: 1,346,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss='binary_crossentropy',optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "U8buwzhPX5v6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_history = model_3.fit(X_train,y_train,\n",
        "            epochs=5,\n",
        "            validation_data=(X_test,y_test),\n",
        "            callbacks=create_tensorboard_callback(SAVE_DIR,'model_3_GRU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8omX4xvffk-",
        "outputId": "8ad54487-ee70-4486-c7ca-26468d255b8d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20220516-163549\n",
            "Epoch 1/5\n",
            "203/203 [==============================] - 11s 27ms/step - loss: 0.1532 - accuracy: 0.9458 - val_loss: 0.7899 - val_accuracy: 0.7767\n",
            "Epoch 2/5\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.0822 - accuracy: 0.9700 - val_loss: 0.7620 - val_accuracy: 0.7644\n",
            "Epoch 3/5\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.0659 - accuracy: 0.9747 - val_loss: 1.2688 - val_accuracy: 0.7706\n",
            "Epoch 4/5\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.0518 - accuracy: 0.9776 - val_loss: 1.5890 - val_accuracy: 0.7426\n",
            "Epoch 5/5\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.0469 - accuracy: 0.9767 - val_loss: 1.2632 - val_accuracy: 0.7671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_preds = tf.squeeze(tf.round(model_3.predict(X_test)))\n",
        "\n",
        "calculate_results(y_test,model_3_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GugDOyGHf0Rw",
        "outputId": "4850e80e-1df2-4dbd-d38c-b8eb7ae49915"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.70753064798599,\n",
              " 'f1': 0.7649114938571001,\n",
              " 'precision': 0.7674054284930486,\n",
              " 'recall': 0.7670753064798599}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: Bidirectional"
      ],
      "metadata": {
        "id": "7T9YoAoKgL3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(1,),dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64,return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs,outputs,name='model_4_bidirectional')"
      ],
      "metadata": {
        "id": "qfcr6n4tlVyJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0cwmMJumVMa",
        "outputId": "4ec64af1-fa68-457b-a388-06c9cf49dc11"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 15, 128)          98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss='binary_crossentropy',optimizer='Adam',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xAtx44-xmajy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_history = model_4.fit(X_train,y_train,\n",
        "                              epochs=5,\n",
        "                              validation_data=(X_test,y_test),\n",
        "                              callbacks=create_tensorboard_callback(SAVE_DIR,'model_4_bidirectional'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHu_m1q3nFQn",
        "outputId": "7bec8eb3-bdbe-464f-c17a-929e5440d8c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20220516-163616\n",
            "Epoch 1/5\n",
            "203/203 [==============================] - 16s 45ms/step - loss: 0.0976 - accuracy: 0.9700 - val_loss: 0.9188 - val_accuracy: 0.7758\n",
            "Epoch 2/5\n",
            "203/203 [==============================] - 7s 33ms/step - loss: 0.0516 - accuracy: 0.9765 - val_loss: 1.3627 - val_accuracy: 0.7478\n",
            "Epoch 3/5\n",
            "203/203 [==============================] - 6s 28ms/step - loss: 0.0445 - accuracy: 0.9768 - val_loss: 1.2825 - val_accuracy: 0.7750\n",
            "Epoch 4/5\n",
            "203/203 [==============================] - 5s 24ms/step - loss: 0.0398 - accuracy: 0.9791 - val_loss: 1.4211 - val_accuracy: 0.7644\n",
            "Epoch 5/5\n",
            "203/203 [==============================] - 5s 24ms/step - loss: 0.0370 - accuracy: 0.9808 - val_loss: 1.6781 - val_accuracy: 0.7750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_preds = tf.squeeze(tf.round(model_4.predict(X_test)))\n",
        "\n",
        "calculate_results(y_test,model_4_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVihxQaqndlV",
        "outputId": "2efa6942-b29d-4456-8e5b-d40ca96c45d8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.49562171628722,\n",
              " 'f1': 0.7732582150276275,\n",
              " 'precision': 0.7749850420227321,\n",
              " 'recall': 0.7749562171628721}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks for text"
      ],
      "metadata": {
        "id": "5KWFSr2Xtdi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5"
      ],
      "metadata": {
        "id": "kvwslLPvtjeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(1,),dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64,kernel_size=5,\n",
        "                  activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs,outputs,name='model_5_Conv1D')\n",
        "\n",
        "# Compile\n",
        "model_5.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',metrics=['accuracy'])\n",
        "\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "_T0pM5UhuHCK",
        "outputId": "b85ce0c6-c8c4-4f21-8212-80b524566d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_history = model_5.fit(X_train,y_train,\n",
        "                              epochs=5,\n",
        "                              validation_data=(X_test,y_test),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,'Conv1D')])"
      ],
      "metadata": {
        "id": "4vUiCCVNxVqL",
        "outputId": "1c961f33-4fbb-4171-fe4d-41831b9ba77d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20220516-164912\n",
            "Epoch 1/5\n",
            "203/203 [==============================] - 11s 13ms/step - loss: 0.1233 - accuracy: 0.9595 - val_loss: 0.8913 - val_accuracy: 0.7741\n",
            "Epoch 2/5\n",
            "203/203 [==============================] - 3s 12ms/step - loss: 0.0712 - accuracy: 0.9734 - val_loss: 1.0357 - val_accuracy: 0.7680\n",
            "Epoch 3/5\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.0575 - accuracy: 0.9773 - val_loss: 1.0876 - val_accuracy: 0.7706\n",
            "Epoch 4/5\n",
            "203/203 [==============================] - 2s 12ms/step - loss: 0.0514 - accuracy: 0.9784 - val_loss: 1.2022 - val_accuracy: 0.7767\n",
            "Epoch 5/5\n",
            "203/203 [==============================] - 2s 12ms/step - loss: 0.0482 - accuracy: 0.9799 - val_loss: 1.1793 - val_accuracy: 0.7627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_preds = tf.squeeze(tf.round(model_5.predict(X_test)))\n",
        "\n",
        "calculate_results(y_test,model_5_preds)"
      ],
      "metadata": {
        "id": "ThnStMZCxoIa",
        "outputId": "00a4a921-9b2f-4970-b99a-2febfe571cc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.26970227670753,\n",
              " 'f1': 0.7615624856623218,\n",
              " 'precision': 0.762056504701221,\n",
              " 'recall': 0.7626970227670753}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 6: Pretrained (TF Hub)"
      ],
      "metadata": {
        "id": "rh5EAgsLyNeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "j9SXGHSQyR1u"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Keras Layer using the USE pretrained layer \n",
        "sentence_encoder = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "                                  input_shape=[],dtype='string',trainable=False,\n",
        "                                  name='USE')"
      ],
      "metadata": {
        "id": "cRRt9lVP01si"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using Sequential API\n",
        "model_6 = tf.keras.Sequential([sentence_encoder,\n",
        "                               layers.Dense(64,activation='relu'),\n",
        "                               layers.Dense(1,activation='sigmoid')],\n",
        "                              name='model_6_USE')\n",
        "model_6.compile(loss='binary_crossentropy',\n",
        "                optimizer='Adam',metrics=['accuracy'])\n",
        "model_6.summary()"
      ],
      "metadata": {
        "id": "XsflaBB-14HC",
        "outputId": "4fa026b2-9358-4256-a2c3-a350a4e7afa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_history = model_6.fit(X_train,y_train,epochs=5,validation_data=(X_test,y_test),\n",
        "            callbacks=[create_tensorboard_callback(SAVE_DIR,'USE')])"
      ],
      "metadata": {
        "id": "IHq938u42Y4C",
        "outputId": "d0bd47b0-3ab3-4b7a-e912-61d4cc0b1c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/USE/20220516-171603\n",
            "Epoch 1/5\n",
            "203/203 [==============================] - 5s 21ms/step - loss: 0.5089 - accuracy: 0.7855 - val_loss: 0.4595 - val_accuracy: 0.7925\n",
            "Epoch 2/5\n",
            "203/203 [==============================] - 4s 19ms/step - loss: 0.4116 - accuracy: 0.8170 - val_loss: 0.4556 - val_accuracy: 0.7960\n",
            "Epoch 3/5\n",
            "203/203 [==============================] - 4s 18ms/step - loss: 0.3972 - accuracy: 0.8209 - val_loss: 0.4518 - val_accuracy: 0.7977\n",
            "Epoch 4/5\n",
            "203/203 [==============================] - 4s 18ms/step - loss: 0.3894 - accuracy: 0.8266 - val_loss: 0.4520 - val_accuracy: 0.8082\n",
            "Epoch 5/5\n",
            "203/203 [==============================] - 4s 19ms/step - loss: 0.3847 - accuracy: 0.8283 - val_loss: 0.4496 - val_accuracy: 0.8047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_preds = tf.squeeze(tf.round(model_6.predict(X_test)))\n",
        "\n",
        "calculate_results(y_test,model_6_preds)"
      ],
      "metadata": {
        "id": "aSW2nQvv23kq",
        "outputId": "71e0bfb0-79ae-462d-8dd5-1782f98fc9bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.47285464098074,\n",
              " 'f1': 0.8036023364361472,\n",
              " 'precision': 0.8048113712814872,\n",
              " 'recall': 0.8047285464098074}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The same but with 10% of data"
      ],
      "metadata": {
        "id": "MymkgKrK37MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_7 = tf.keras.models.clone_model(model_6)"
      ],
      "metadata": {
        "id": "kzIeNZWb39Hz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esto está mal, algunas de las muestras del entrenamiento quedan adentro de la validación.\n",
        "train_01 = train_df_shuffled[['text','target']].sample(frac=0.1,random_state=42)\n",
        "\n",
        "X_train_01 = train_01['text'].to_list()\n",
        "y_train_01 = train_01['target'].to_list()"
      ],
      "metadata": {
        "id": "niFnQMQF4IM5"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.compile(loss='binary_crossentropy',optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_7.fit(X_train_01,y_train_01,\n",
        "            epochs=5,validation_data=(X_test,y_test),\n",
        "            callbacks=[create_tensorboard_callback(SAVE_DIR,'USE_10p')])"
      ],
      "metadata": {
        "id": "ppUsne_m5Qf1",
        "outputId": "cd2796b4-8463-4566-a677-092a4f3d78c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/USE_10p/20220516-172537\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 8s 119ms/step - loss: 0.6725 - accuracy: 0.6518 - val_loss: 0.6371 - val_accuracy: 0.7881\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 2s 83ms/step - loss: 0.5983 - accuracy: 0.7871 - val_loss: 0.5650 - val_accuracy: 0.7872\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 2s 90ms/step - loss: 0.5223 - accuracy: 0.7937 - val_loss: 0.4997 - val_accuracy: 0.7872\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 2s 87ms/step - loss: 0.4639 - accuracy: 0.7989 - val_loss: 0.4611 - val_accuracy: 0.7960\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 2s 86ms/step - loss: 0.4269 - accuracy: 0.8134 - val_loss: 0.4379 - val_accuracy: 0.7986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7dbc9abd90>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "10_NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVmYbp83J3iz8+ZIeAm13q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}