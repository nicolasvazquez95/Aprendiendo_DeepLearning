{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae36b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1e64acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d2f7f",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c9e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_moons(n_samples=500,noise=0.3,random_state=42)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df4c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a4650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr',log_clf),\n",
    "                                         ('rf',rnd_clf),\n",
    "                                         ('svc',svm_clf)],\n",
    "                             voting='hard')\n",
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb3a495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e51660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo con predict_proba\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c193617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(probability=True, random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr',log_clf),\n",
    "                                         ('rf',rnd_clf),\n",
    "                                         ('svc',svm_clf)],\n",
    "                             voting='soft')\n",
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8740bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc7557",
   "metadata": {},
   "source": [
    "# Bagging/pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd2df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c11abe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           n_estimators = 500,max_samples=100,\n",
    "                           bootstrap=True,n_jobs=-1)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a6efe",
   "metadata": {},
   "source": [
    "## OOB Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfd8518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           n_estimators=500,bootstrap=True,\n",
    "                           n_jobs=-1,oob_score=True)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4ae5f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce8be26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38624339, 0.61375661])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e0b4c",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "8. Load the MNIST data (introduced in Chapter 3), and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing). Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM classifier. Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e0036b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26aaa6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = fetch_openml('mnist_784',return_X_y=True,as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c8b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = X[:50000],y[:50000]\n",
    "X_valid,y_valid = X[50000:60000],y[50000:60000]\n",
    "X_test,y_test = X[60000:],y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c24b01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier 0.9743\n",
      "RandomForestClassifier 0.9736\n",
      "SVC 0.9802\n",
      "VotingClassifier 0.9813\n"
     ]
    }
   ],
   "source": [
    "et_clf = ExtraTreesClassifier(random_state=42,n_jobs=-1)\n",
    "rnd_clf = RandomForestClassifier(random_state=42,n_jobs=-1)\n",
    "svm_clf = SVC(random_state=42,probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr',et_clf),\n",
    "                                         ('rf',rnd_clf),\n",
    "                                         ('svc',svm_clf)],\n",
    "                             voting='soft',n_jobs=-1)\n",
    "\n",
    "for clf in (et_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_valid,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4bd7ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier 0.9703\n",
      "RandomForestClassifier 0.968\n",
      "SVC 0.9785\n",
      "VotingClassifier 0.9783\n"
     ]
    }
   ],
   "source": [
    "for clf in (et_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503301ee",
   "metadata": {},
   "source": [
    "9. Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image’s class. Train a classifier on this new training set. Congratulations, you have just trained a blender, and together with the classifiers it forms a stacking ensemble! Now evaluate the ensemble on the test set. For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensemble’s predictions. How does it compare to the voting classifier you trained earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aee0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_et = et_clf.predict(X_valid)\n",
    "y_valid_rnd = rnd_clf.predict(X_valid)\n",
    "y_valid_svm = svm_clf.predict(X_valid)\n",
    "x_train_blender = np.c_[y_valid_et,y_valid_rnd,y_valid_svm]\n",
    "y_train_blender = y_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd9ace3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_et = et_clf.predict(X_test)\n",
    "y_test_rnd = rnd_clf.predict(X_test)\n",
    "y_test_svm = svm_clf.predict(X_test)\n",
    "x_test_blender = np.c_[y_test_et,y_test_rnd,y_test_svm]\n",
    "y_test_blender = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "x_train_blender = ohe.fit_transform(x_train_blender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "554062f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_blender = ohe.fit_transform(x_test_blender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74a76197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.9762\n",
      "DecisionTreeClassifier 0.9751\n",
      "ExtraTreesClassifier 0.9753\n",
      "KNeighborsClassifier 0.9745\n"
     ]
    }
   ],
   "source": [
    "### Entrenemos un par de modelos, y veamos qué onda\n",
    "rf_clf = RandomForestClassifier(random_state=42,max_features=6,n_jobs=-1)\n",
    "dt_clf = DecisionTreeClassifier(random_state=42,max_features=6)\n",
    "et_clf_ = ExtraTreesClassifier(random_state=42,max_features=6)\n",
    "kn_clf = KNeighborsClassifier(n_jobs=-1)\n",
    "for clf in (rf_clf,dt_clf,et_clf_,kn_clf):\n",
    "    clf.fit(x_train_blender,y_train_blender)\n",
    "    y_pred_blender = clf.predict(x_test_blender)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test_blender,y_pred_blender))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5665330b",
   "metadata": {},
   "source": [
    "Funcan más o menos igual el blender con el voting classifier (este erra en más o menos 20 instancias más, pero creo que ese error es despreciable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
